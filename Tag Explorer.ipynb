{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Explorer\n",
    "\n",
    "<b>Version:</b> Draft <br/>\n",
    "<b>Description:</b> This kernel contains the code required to make the final code.<br/>\n",
    "<b>Warning:</b><br/>\n",
    "1. This is a side draft.\n",
    "2. Change the <i>Initialization</i> variables according to your system before using the program.<br/>\n",
    "3. Install all the packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import xlwt\n",
    "\n",
    "keyDir = r'\\\\brdieshnas1\\AMS\\SOFTWARE_REPOSITORY\\Python\\Well logs.xlsx'\n",
    "\n",
    "def ReadExcel():        \n",
    "    \n",
    "    KeywordList = []\n",
    "    workbook = xlrd.open_workbook(keyDir)\n",
    "    sheet=workbook.sheet_by_index(1)\n",
    "    \n",
    "\n",
    "    data = [[sheet.cell_value(r,c) for c in range(sheet.ncols)] for r in range (sheet.nrows)]\n",
    "    \n",
    "        \n",
    "    for row in range(1,sheet.nrows):\n",
    "        KeywordList.append(data[row][2].strip())\n",
    "    \n",
    "    print(KeywordList)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    ReadExcel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 2 (Draft 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "docTitle = ['RADIOACTIVITY LOG', 'ELECTRICAL LOG', 'COMPENSATED NEUTRON LOG', 'BOREHOLE COMPENSATED DENSITY LOG', 'DUAL INDUCTION LOG', 'DUAL INDUCTION LATERLOG', 'ELECTRICAL LOG', 'TEMPERATURE LOG', 'SONIC GAMMA RAY LOG', 'LATEROLOG', 'GAMMA RAY NEUTRON LOG']\n",
    "for i in range(0, len(docTitle)):\n",
    "    docTitle[i] = docTitle[i].lower()\n",
    "    \n",
    "description = ['Gamma Ray', 'Caliper', 'Resistivity', 'Deep Resistivity', 'Shallow Resistivity', 'Conductivity', 'Spontaneous Potential', 'Bulk Density', 'Density Correction', 'Density', 'Neutron Porosity', 'Porosity', 'Formation Density', 'Acoustic/Sonic', 'Cement Bond Log', 'Variation Density Log', 'Lithology', 'Drilling', 'Bit Size', 'Tension', 'Dip Meter', 'Neutron Porosity Limestone Matrix', 'Neutron Porosity Limestone', 'Production', 'Casing Collar Locator', 'Differential Caliper', 'Temperature', 'Permeability', 'Amplitude Spherical Focussed Log', 'Deviation Curve', 'Stratigraphic Log', 'Water Saturation', 'Pressure', 'Neutron', 'Mud Log', 'Side Wall Core Analysis', 'Environment', 'Palaeontology', 'Forecast', 'Geochemistry', 'Velocity Function (Two-Way Time)']\n",
    "for i in range(0, len(description)):\n",
    "    description[i] = description[i].lower()\n",
    "    \n",
    "    \n",
    "docTitleLine = []\n",
    "descriptionLine = []\n",
    "\n",
    "inpDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Input - JSON'\n",
    "keyword = \"text\"\n",
    "keyword1 = \"words\"\n",
    "\n",
    "#Reading file by file\n",
    "def readfile() :\n",
    "    try:\n",
    "        for root, dirs, filenames in os.walk(inpDir):\n",
    "            for f in filenames :\n",
    "                print('\\033[1m' + \"For\", f + '\\033[0m')\n",
    "                file1 = (os.path.join(inpDir, f))            \n",
    "                readtext(file1,f)\n",
    "                print(\"\")\n",
    "    except Exception as e:\n",
    "        print(\"Problem in readfile():\", e)\n",
    "\n",
    "#Reading a file line by line            \n",
    "def readtext(file1,f):\n",
    "    try:\n",
    "        \n",
    "        with open(file1) as ff: \n",
    "            lines = ff.readlines()   \n",
    "            \n",
    "            for i in range(0, len(lines)):\n",
    "                line = lines[i]\n",
    "                \n",
    "                if (keyword in line) and (keyword1 in lines[i+1]):\n",
    "                    #print(line)\n",
    "                    \n",
    "                    tempString = line.strip().replace(\"\\\"text\\\": \",\"\").replace(\",\",\"\").replace('\"','')\n",
    "                    \n",
    "                #print(\"-----------------\")\n",
    "                if (keyword in line) and (keyword1 in lines[i+1]):\n",
    "                    \n",
    "                    for docTitleKey in docTitle:\n",
    "                        if docTitleKey in tempString.lower():\n",
    "                            #print(\"\")\n",
    "                            #print(tempString,\": DocTitle\")\n",
    "                            docTitleLine.append(tempString)\n",
    "                    for descriptionKey in description:\n",
    "                        if descriptionKey in tempString.lower():\n",
    "                            descriptionLine.append(tempString)\n",
    "                            \n",
    "            print(\"DocTitles\")\n",
    "            print(docTitleLine)\n",
    "            print(\"\")\n",
    "            print(\"Description\")\n",
    "            print(descriptionLine)\n",
    "                        \n",
    "    except Exception as e:\n",
    "        print(\"Exception:\",e)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    readfile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 3 (Draft1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 1 (Draft 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Keywords (Draft 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "keyDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Keywords\\Keywords2.xlsx'\n",
    "key=''\n",
    "\n",
    "def ReadExcel(key):        \n",
    "        \n",
    "    workbook = xlrd.open_workbook(keyDir) \n",
    "    \n",
    "        \n",
    "    dfKey = pd.read_excel(keyDir, sheetname='Keywords')\n",
    "\n",
    "    try:\n",
    "        index = np.where(dfKey['Keywords']==key)[0][0]\n",
    "        print(index)\n",
    "        print(\"Sub Category:\", dfKey['Sub-Category'][index])\n",
    "        print(\"Category:\",dfKey['Category'][index])\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "#if __name__ == \"__main__\":\n",
    "    #ReadExcel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Keywords (Draft 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "keyDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Keywords\\Keywords2.xlsx'\n",
    "\n",
    "def ReadExcel():        \n",
    "        \n",
    "    workbook = xlrd.open_workbook(keyDir)\n",
    "       \n",
    "    key='Lithology column'\n",
    "        \n",
    "    dfKey = pd.read_excel(keyDir, sheetname='Keywords')\n",
    "\n",
    "    try:\n",
    "        for iterateKeys in range(0, len(dfKey['Keywords'])):\n",
    "            #print(type(dfKey['Keywords'][iterateKeys]))\n",
    "            if dfKey['Keywords'][iterateKeys].lower() in key.lower() :\n",
    "                print(iterateKeys)             \n",
    "        \n",
    "                print(\"Sub Category:\", dfKey['Sub-Category'][iterateKeys])\n",
    "                print(\"Category:\",dfKey['Category'][iterateKeys])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Exception:\",e)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "if __name__ == \"__main__\":\n",
    "    ReadExcel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity (Draft 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "keyDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Keywords\\Keywords2.xlsx'\n",
    "workbook = xlrd.open_workbook(keyDir)\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "dfKey = pd.read_excel(keyDir, sheetname='Keywords')\n",
    "\n",
    "key = 'Lithology'\n",
    "max1 = 0\n",
    "word = ''\n",
    "for iterateKeys in range(0, len(dfKey['Keywords'])):\n",
    "    if max1 < similar(key, dfKey['Keywords'][iterateKeys]):\n",
    "        max1 = similar(key, dfKey['Keywords'][iterateKeys])\n",
    "        word = dfKey['Keywords'][iterateKeys]\n",
    "        \n",
    "print(max1,\" \", word)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"\\nExecution Time:\",end-start)ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity (Draft 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "keyDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Keywords\\Keywords2.xlsx'\n",
    "inpDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Input - Text\\a'\n",
    "workbook = xlrd.open_workbook(keyDir)\n",
    "dfKey = pd.read_excel(keyDir, sheetname='Keywords')\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def readfile() :\n",
    "    try:\n",
    "        for root, dirs, filenames in os.walk(inpDir):\n",
    "            for f in filenames :\n",
    "                print('\\033[1m' + \"For\", f + '\\033[0m')\n",
    "                file1 = (os.path.join(inpDir, f))            \n",
    "                readtext(file1,f)\n",
    "                #print(\"\")\n",
    "    except Exception as e:\n",
    "        print(\"Problem in readfile():\", e)\n",
    "\n",
    "#Reading a file line by line            \n",
    "def readtext(file1,f):\n",
    "    try:\n",
    "\n",
    "        with open(file1) as ff: \n",
    "            lines = ff.readlines()   \n",
    "\n",
    "            for i in range(0, len(lines)):\n",
    "                line = lines[i]\n",
    "                line1 = nltk.word_tokenize(line)\n",
    "                \n",
    "                \n",
    "                for listItem in line1:\n",
    "                    key=listItem\n",
    "                    max1 = 0\n",
    "                    word = ''\n",
    "                    for iterateKeys in range(0, len(dfKey['Keywords'])):\n",
    "                        if max1 < similar(key, dfKey['Keywords'][iterateKeys]):\n",
    "                            max1 = similar(key, dfKey['Keywords'][iterateKeys])\n",
    "                            word = dfKey['Keywords'][iterateKeys]\n",
    "\n",
    "                    if max1>0.2:\n",
    "                        print(key, \" \",max1,\" \", word)\n",
    "\n",
    "        \n",
    "        \n",
    "                \n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Exception:\",e)\n",
    "    \n",
    "    print(\"\")\n",
    "if __name__ == '__main__':\n",
    "    readfile()\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"\\nExecution Time:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity (Draft 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import difflib as dl\n",
    "from nltk import ngrams\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "keyDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Keywords\\Keywords2.xlsx'\n",
    "inpDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Input - Text\\a'\n",
    "workbook = xlrd.open_workbook(keyDir)\n",
    "dfKey = pd.read_excel(keyDir, sheetname='Keywords')\n",
    "\n",
    "def similar(a, b):\n",
    "    return dl.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def readfile() :\n",
    "    try:\n",
    "        for root, dirs, filenames in os.walk(inpDir):\n",
    "            for f in filenames :\n",
    "                print('\\033[1m' + \"For\", f + '\\033[0m')\n",
    "                file1 = (os.path.join(inpDir, f))            \n",
    "                readtext(file1,f)\n",
    "                #print(\"\")\n",
    "    except Exception as e:\n",
    "        print(\"Problem in readfile():\", e)\n",
    "\n",
    "#Reading a file line by line            \n",
    "def readtext(file1,f):\n",
    "    try:\n",
    "\n",
    "        with open(file1) as ff: \n",
    "            lines = ff.readlines()   \n",
    "\n",
    "            for i in range(0, len(lines)):\n",
    "                line = lines[i]\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                for iterateKeys in range(0, len(dfKey['Keywords'])):\n",
    "                    \n",
    "                    n = len(dfKey['Keywords'][iterateKeys].split(\" \"))\n",
    "                    \n",
    "                    try:\n",
    "                        sixgrams = ngrams(line.split(), n)   \n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                    max1 = 0 \n",
    "                    for grams in sixgrams:\n",
    "                        #print(grams)\n",
    "                        str1 = ' '.join(grams)\n",
    "                        \n",
    "                        key=str1\n",
    "                        \n",
    "                        \n",
    "                        word = ''\n",
    "                        if max1 < similar(key, dfKey['Keywords'][iterateKeys]):\n",
    "                            max1 = similar(key, dfKey['Keywords'][iterateKeys])\n",
    "                            word = dfKey['Keywords'][iterateKeys]\n",
    "                            #print(dfKey['Keywords'][iterateKeys])\n",
    "                            #print(key,\",\", dfKey['Keywords'][iterateKeys])\n",
    "                            #print(dl.get_close_matches(key,dfKey['Keywords']))\n",
    "                            \n",
    "\n",
    "                    if max1>0.5:\n",
    "                        print(key, \" \",max1,\" \", word)\n",
    "                        print(dl.get_close_matches(key,dfKey['Keywords']))\n",
    "                \n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Exception:\",e)\n",
    "    \n",
    "    print(\"\")\n",
    "if __name__ == '__main__':\n",
    "    readfile()\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"\\nExecution Time:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity (Draft 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import difflib as dl\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from nltk import ngrams\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "keyDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Keywords\\Keywords2.xlsx'\n",
    "inpDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Input - Text\\a'\n",
    "workbook = xlrd.open_workbook(keyDir)\n",
    "dfKey = pd.read_excel(keyDir, sheetname='Keywords')\n",
    "\n",
    "def similar(a, b):\n",
    "    return dl.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def readfile() :\n",
    "    try:\n",
    "        for root, dirs, filenames in os.walk(inpDir):\n",
    "            for f in filenames :\n",
    "                print(\"-\"*40)\n",
    "                print('\\033[1m' + \"For\", f + '\\033[0m')\n",
    "                file1 = (os.path.join(inpDir, f))            \n",
    "                readtext(file1,f)\n",
    "                #print(\"\")\n",
    "    except Exception as e:\n",
    "        print(\"Problem in readfile():\", e)\n",
    "\n",
    "#Reading a file line by line            \n",
    "def readtext(file1,f):\n",
    "    try:\n",
    "        mean = 0\n",
    "        count = 0\n",
    "        with open(file1) as ff: \n",
    "            lines = ff.readlines()   \n",
    "\n",
    "            for i in range(0, len(lines)):\n",
    "               \n",
    "                \n",
    "                line = lines[i]\n",
    "                \n",
    "                if line.strip() == '':\n",
    "                    continue\n",
    "                #line1 = nltk.word_tokenize(line)\n",
    "                #print('\\033[1m' + \"Line:\",line+ '\\033[0m')\n",
    "                max1=0\n",
    "                found = 0\n",
    "                for iterateKeys in range(0, len(dfKey['Keywords'])):\n",
    "                    n = len(dfKey['Keywords'][iterateKeys].strip().split(\" \"))\n",
    "                    \n",
    "                    sixgrams = ngrams(line.split(), n)\n",
    "                    word = None\n",
    "                    \n",
    "                    for grams in sixgrams:\n",
    "                        \n",
    "                        str1 = ' '.join(grams)\n",
    "                        key=str1\n",
    "                        keyword1 = dfKey['Keywords'][iterateKeys]\n",
    "                                         \n",
    "                        max1 = similar(key.lower(), keyword1.lower())\n",
    "                        \n",
    "                        \n",
    "                        if max1>0.8:\n",
    "                            count+=1\n",
    "                            mean+=max1\n",
    "                            #print('\\033[1m' + \"Line:\",line+ '\\033[0m')\n",
    "                            print(\"Keyword:\",dfKey['Keywords'][iterateKeys])\n",
    "                            #print(\"Length:\", n)\n",
    "                            #print(\"Grams:\",grams)\n",
    "                            word = keyword1 \n",
    "                            #print(key, \" \",max1,\" \", word)\n",
    "                            #print(dl.get_close_matches(key,dfKey['Keywords']))\n",
    "                            print(\"\")\n",
    "                            found=1               \n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Exception:\",e)\n",
    "    \n",
    "    print(\"\")\n",
    "    if count==0:\n",
    "        print(\"No Keyword\")\n",
    "    else:\n",
    "        mean=mean/count\n",
    "    #print(\"Count:\", count)\n",
    "    #print(\"Mean:\",mean)\n",
    "if __name__ == '__main__':\n",
    "    readfile()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"\\nExecution Time:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dict = {'Well Logs':['A1','A2','A3','A4','A5','A6','A7']}\n",
    "dict_types = {'A1':'Annotated','A2':'A2','A3':'A3','A4':'A4','A5':'A5','A6':'A6','A7':'A7'}\n",
    "dict_types_keys = {'A1':[],'A2':[],'A3':[],'A4':[],'A5':[],'A6':[],'A7':[]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1={0:'Well Log', 1:'Formation Evaluation', 2:'Velocity',3:'Drilling'}\n",
    "dict2={0:'Annotated',1:}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1=[]\n",
    "list2=['A1: Annotated','A2: Cased Hole','A3: Composite', 'A4: Field', 'A5: Final', 'A6: LWD/MWD', 'A7: `MUD/SAMPLE LOG','B1: CORE', 'B2: GEOCHEMICAL','B3: LABORATORY / SAMPLE REPORT','C1: PROCESSED', 'D1: PLANNING/ANALYSIS']\n",
    "dict2={0:'Well Log', 1:'Formation Evaluation', 2:'Velocity',3:'Drilling'}\n",
    "dict1={}\n",
    "list3=['Core' , 'SWC(depth -m)', 'Formation Tops', 'Tests(DST,RFT,SFT,FMT)', 'Perforation', 'Oil and Gas show']\n",
    "for i in range(0,31):\n",
    "    if i <7:\n",
    "        list1.append('0'+str(i))\n",
    "        dict1['0'+str(i)] = list2[i]\n",
    "        \n",
    "    if i>=10 and i<=12:\n",
    "        list1.append(str(i))\n",
    "        dict1[str(i)] = list2[i-10+7]\n",
    "    if i==20:\n",
    "        list1.append(str(i))\n",
    "        dict1[str(i)] = list2[i-20+10]\n",
    "    if i==30:\n",
    "        list1.append(str(i))\n",
    "        dict1[str(i)] = list2[i-30+11]\n",
    "        \n",
    "        \n",
    "print(list1)\n",
    "print(\"\")\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "print(similar(\"Ray\", \"the\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "sentence = 'this is a foo bar sentences and i want to ngramize it'\n",
    "n = 3\n",
    "sixgrams = ngrams(sentence.split(), n)\n",
    "count = 0\n",
    "print(sixgrams[1])\n",
    "for grams in sixgrams:\n",
    "    if count == 1:\n",
    "        print(grams)\n",
    "        str1 = ' '.join(grams)\n",
    "        print(str1)\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autocorrect import spell\n",
    "spell('L0G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

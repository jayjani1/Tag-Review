{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Categories, Sub-Categories along with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\u001b[1mFor Baker Hughes_2001.txt\u001b[0m\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Core\n",
      "Sub Category: Annotated\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Casing Record\n",
      "Sub Category: Cased Hole\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Baker Hughes_2012.txt\u001b[0m\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: LWD\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: LWD\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Bit Size\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: MUD\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: MUD\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Haliburton_1946.txt\u001b[0m\n",
      "Keyword: SWC\n",
      "Sub Category: Annotated\n",
      "Category: Well Logs\n",
      "SWC :   \n",
      "  \n",
      "\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Haliburton_1993.txt\u001b[0m\n",
      "Keyword: Perforation\n",
      "Sub Category: Annotated\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Bit Size\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Haliburton_2008.txt\u001b[0m\n",
      "Keyword: ROP\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "ROP :  359565 254Z 0 Z WI 0 0 UJ 0  \n",
      " 359565 254Z 0 Z WI 0 0 UJ 0  \n",
      "\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Core\n",
      "Sub Category: Annotated\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Reeves_2001.txt\u001b[0m\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Bit Size\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Title\n",
      "Sub Category: FINAL\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Schlumberger_2010.txt\u001b[0m\n",
      "\n",
      "No Keyword\n",
      "----------------------------------------\n",
      "\u001b[1mFor Schlumberger_2014.txt\u001b[0m\n",
      "\n",
      "No Keyword\n",
      "----------------------------------------\n",
      "\u001b[1mFor Weatherford_2006.txt\u001b[0m\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Weatherford_2011.txt\u001b[0m\n",
      "Keyword: Perforation\n",
      "Sub Category: Annotated\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Weatherford_2014.txt\u001b[0m\n",
      "Keyword: SWC\n",
      "Sub Category: Annotated\n",
      "Category: Well Logs\n",
      "SWC :   \n",
      "  \n",
      "\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: Bit Size\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: MUD\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "None\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Western Atlas_1998.txt\u001b[0m\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "SAMPLE :  FL OWLI NE  \n",
      " FL OWLI NE  \n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor wrongKEYWORDLIST.txt\u001b[0m\n",
      "\n",
      "No Keyword\n",
      "\n",
      "Execution Time: 7.125999689102173\n"
     ]
    }
   ],
   "source": [
    "import difflib as dl\n",
    "import xlrd\n",
    "import xlwt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from nltk import ngrams\n",
    "import nltk\n",
    "import warnings\n",
    "import re \n",
    "import logging\n",
    "from openpyxl import Workbook, load_workbook\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "start = time.time()\n",
    "keyDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Keywords\\Keywords2.xlsx'\n",
    "#inpDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Input - Text\\a'\n",
    "inpDir = r'\\\\brdieshnas1\\AMS\\SOFTWARE_REPOSITORY\\Python\\Auchinto Chatterjee\\Autocorrect + Categorise\\Well_Refined_TXT'\n",
    "workbook = xlrd.open_workbook(keyDir)\n",
    "dfKey = pd.read_excel(keyDir, sheetname='Keywords')\n",
    "printPath = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Output\\PythonExport.xls'\n",
    "wb = xlwt.Workbook()\n",
    "ws = wb.add_sheet('Sheet1')\n",
    "global row\n",
    "row = 0\n",
    "ws.write(row,0,\"File\")\n",
    "ws.write(row,1,\"Category\")\n",
    "ws.write(row,2,\"Sub-Category\")\n",
    "ws.write(row,3,\"Keyword\")\n",
    "ws.write(row,4,\"Value\")\n",
    "\n",
    "def PrintException():\n",
    "    import sys\n",
    "    import linecache\n",
    "    exc_type, exc_obj, tb = sys.exc_info()\n",
    "    f = tb.tb_frame\n",
    "    lineno = tb.tb_lineno\n",
    "    filename = f.f_code.co_filename\n",
    "    linecache.checkcache(filename)\n",
    "    line = linecache.getline(filename, lineno, f.f_globals)\n",
    "    print('EXCEPTION IN ({}, LINE {} \"{}\"): {}'.format(filename, lineno, line.strip(), exc_obj))\n",
    "\n",
    "\n",
    "class ExtractData():\n",
    "    \n",
    "    def __init__(self,Key_list,Input_Path):\n",
    "        self.Key_list = Key_list\n",
    "        self.Input_Path = Input_Path\n",
    "        \n",
    "    def read_text(self):\n",
    "        \n",
    "        text = self.Input_Path.read()\n",
    "        a = None\n",
    "        for line in text.splitlines():\n",
    "            a = self.match_keyword(line,text)\n",
    "            if a!= None:\n",
    "                return a\n",
    "       \n",
    "    def match_keyword(self,line,text):\n",
    "        \n",
    "        starting_index = []\n",
    "        for key in self.Key_list:\n",
    "            if key in line:\n",
    "                match_iter = re.finditer(key, line)\n",
    "\n",
    "                for match in match_iter:\n",
    "                    matched_text = [match.group(0)]\n",
    "                    x = match.start()\n",
    "                   \n",
    "                    starting_index.append(x)       \n",
    "            else:\n",
    "                starting_index.append(-1)\n",
    "        sort_string = sorted(starting_index)\n",
    "        \n",
    "\n",
    "        length = len(sort_string)\n",
    "      \n",
    "        for index,obj in enumerate(sort_string):\n",
    "            if obj != -1:\n",
    "                c = starting_index.index(obj)\n",
    "                   \n",
    "                if (index+1) < length:\n",
    "                    next = sort_string[index + 1]\n",
    "                else:\n",
    "                    next = len(text)\n",
    "              \n",
    "                first = len(self.Key_list[c]) + obj\n",
    "                \n",
    "                print(self.Key_list[c],\":\",line[first:next])\n",
    "                return (line[first:next])\n",
    "                \n",
    "def similar(a, b):\n",
    "    return dl.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def readfile() :\n",
    "    try:\n",
    "        for root, dirs, filenames in os.walk(inpDir):\n",
    "            for f in filenames :\n",
    "                print(\"-\"*40)\n",
    "                print('\\033[1m' + \"For\", f + '\\033[0m')\n",
    "                file1 = (os.path.join(inpDir, f)) \n",
    "                Input_Path = open(file1,'r')\n",
    "                readtext(Input_Path,file1,f)\n",
    "                #print(\"\")\n",
    "    except Exception as e:\n",
    "        print(\"Problem in readfile():\", e)\n",
    "\n",
    "#Reading a file line by line            \n",
    "def readtext(Input_Path,file1,f):\n",
    "    try:\n",
    "        mean = 0\n",
    "        count = 0\n",
    "        with open(file1) as ff: \n",
    "            lines = ff.readlines()   \n",
    "\n",
    "            for i in range(0, len(lines)):\n",
    "               \n",
    "                \n",
    "                line = lines[i]\n",
    "                \n",
    "                if line.strip() == '':\n",
    "                    continue\n",
    "                #line1 = nltk.word_tokenize(line)\n",
    "                #print('\\033[1m' + \"Line:\",line+ '\\033[0m')\n",
    "                max1=0\n",
    "                found = 0\n",
    "                for iterateKeys in range(0, len(dfKey['Keywords'])):\n",
    "                    n = len(dfKey['Keywords'][iterateKeys].strip().split(\" \"))\n",
    "                    \n",
    "                    sixgrams = ngrams(line.split(), n)\n",
    "                    word = None\n",
    "                    \n",
    "                    for grams in sixgrams:\n",
    "                        \n",
    "                        str1 = ' '.join(grams)\n",
    "                        key=str1\n",
    "                        keyword1 = dfKey['Keywords'][iterateKeys]\n",
    "                                         \n",
    "                        max1 = similar(key.lower(), keyword1.lower())\n",
    "                        \n",
    "                        \n",
    "                        if max1>0.8:\n",
    "                            count+=1\n",
    "                            mean+=max1\n",
    "                            #print('\\033[1m' + \"Line:\",line+ '\\033[0m')\n",
    "                            print(\"Keyword:\",dfKey['Keywords'][iterateKeys])\n",
    "                            #print(\"Length:\", n)\n",
    "                            #print(\"Grams:\",grams)\n",
    "                            word = keyword1 \n",
    "                            #print(key, \" \",max1,\" \", word)\n",
    "                            #print(dl.get_close_matches(key,dfKey['Keywords']))\n",
    "                             \n",
    "                            found=1  \n",
    "                            \n",
    "                            try:\n",
    "                                for iterateKeys in range(0, len(dfKey['Keywords'])):\n",
    "                                    list3 = []\n",
    "                                    #print(type(dfKey['Keywords'][iterateKeys]))\n",
    "                                    if dfKey['Keywords'][iterateKeys].lower() in word.lower() :\n",
    "                                        #print(iterateKeys)             \n",
    "                                        list3.append(dfKey['Keywords'][iterateKeys])\n",
    "                                        print(\"Sub Category:\", dfKey['Sub-Category'][iterateKeys])\n",
    "                                        print(\"Category:\",dfKey['Category'][iterateKeys])\n",
    "                                        obj = ExtractData(list3,Input_Path)\n",
    "                                        val = obj.read_text()\n",
    "                                        print(val)\n",
    "                                        \n",
    "                                        global row\n",
    "                                        row+=1\n",
    "                                        ws.write(row,0,f)\n",
    "                                        ws.write(row,1,dfKey['Category'][iterateKeys])\n",
    "                                        ws.write(row,2,dfKey['Sub-Category'][iterateKeys])\n",
    "                                        ws.write(row,3,dfKey['Keywords'][iterateKeys])\n",
    "                                        ws.write(row,4,val)\n",
    "                                        print(\"\")\n",
    "                                        \n",
    "                            except Exception as e:\n",
    "                                PrintException()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Exception:\",e)\n",
    "    \n",
    "    print(\"\")\n",
    "    if count==0:\n",
    "        print(\"No Keyword\")\n",
    "    else:\n",
    "        mean=mean/count\n",
    "    #print(\"Count:\", count)\n",
    "    #print(\"Mean:\",mean)\n",
    "    \n",
    "    #Input_Path1 = Input_Path\n",
    "    \n",
    "    \n",
    "    wb.save(printPath)\n",
    "if __name__ == '__main__':\n",
    "    readfile()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"\\nExecution Time:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Categories, Sub-Categories only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\u001b[1mFor Baker Hughes_2001.txt\u001b[0m\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: Casing Record\n",
      "Sub Category: Cased Hole\n",
      "Category: Well Logs\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Baker Hughes_2012.txt\u001b[0m\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: Bit Size\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: MUD\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: MUD\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Haliburton_1946.txt\u001b[0m\n",
      "\n",
      "No Keyword\n",
      "----------------------------------------\n",
      "\u001b[1mFor Haliburton_1993.txt\u001b[0m\n",
      "Keyword: Bit Size\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Haliburton_2008.txt\u001b[0m\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Reeves_2001.txt\u001b[0m\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "Date :  \n",
      "\n",
      "Keyword: Bit Size\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: Title\n",
      "Sub Category: FINAL\n",
      "Category: Well Logs\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Schlumberger_2010.txt\u001b[0m\n",
      "\n",
      "No Keyword\n",
      "----------------------------------------\n",
      "\u001b[1mFor Schlumberger_2014.txt\u001b[0m\n",
      "\n",
      "No Keyword\n",
      "----------------------------------------\n",
      "\u001b[1mFor Weatherford_2006.txt\u001b[0m\n",
      "\n",
      "No Keyword\n",
      "----------------------------------------\n",
      "\u001b[1mFor Weatherford_2011.txt\u001b[0m\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "Date :  31-MAR-2011 \n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Weatherford_2014.txt\u001b[0m\n",
      "Keyword: Date\n",
      "Sub Category: LWD/MWD\n",
      "Category: Well Logs\n",
      "Date :  31-0CT-2014 I \n",
      "\n",
      "Keyword: Bit Size\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: MUD\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "Keyword: SAMPLE\n",
      "Sub Category: MUD/SAMPLE LOG\n",
      "Category: Well Logs\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\u001b[1mFor Western Atlas_1998.txt\u001b[0m\n",
      "\n",
      "No Keyword\n",
      "\n",
      "Execution Time: 7.646449327468872\n"
     ]
    }
   ],
   "source": [
    "import difflib as dl\n",
    "import xlrd\n",
    "import xlwt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from nltk import ngrams\n",
    "import nltk\n",
    "import warnings\n",
    "import re \n",
    "import logging\n",
    "from openpyxl import Workbook, load_workbook\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "start = time.time()\n",
    "keyDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Keywords\\Keywords2.xlsx'\n",
    "inpDir = r'C:\\Users\\T01144\\Desktop\\Test Cases\\Tag Explorer\\Input - Text\\a'\n",
    "workbook = xlrd.open_workbook(keyDir)\n",
    "dfKey = pd.read_excel(keyDir, sheetname='Keywords')\n",
    "printPath = r'C:\\Users\\T01144\\Desktop\\PythonExport2.xls'\n",
    "wb = xlwt.Workbook()\n",
    "ws = wb.add_sheet('Sheet1')\n",
    "global row\n",
    "row = 0\n",
    "ws.write(row,0,\"File\")\n",
    "ws.write(row,1,\"Category\")\n",
    "ws.write(row,2,\"Sub-Category\")\n",
    "ws.write(row,3,\"Keyword\")\n",
    "\n",
    "def PrintException():\n",
    "    import sys\n",
    "    import linecache\n",
    "    exc_type, exc_obj, tb = sys.exc_info()\n",
    "    f = tb.tb_frame\n",
    "    lineno = tb.tb_lineno\n",
    "    filename = f.f_code.co_filename\n",
    "    linecache.checkcache(filename)\n",
    "    line = linecache.getline(filename, lineno, f.f_globals)\n",
    "    print('EXCEPTION IN ({}, LINE {} \"{}\"): {}'.format(filename, lineno, line.strip(), exc_obj))\n",
    "\n",
    "\n",
    "class ExtractData():\n",
    "    \n",
    "    def __init__(self,Key_list,Input_Path):\n",
    "        self.Key_list = Key_list\n",
    "        self.Input_Path = Input_Path\n",
    "        \n",
    "    def read_text(self):\n",
    "        \n",
    "        text = self.Input_Path.read()\n",
    "\n",
    "        for line in text.splitlines():\n",
    "            a = self.match_keyword(line,text)\n",
    "            \n",
    "    def match_keyword(self,line,text):\n",
    "        \n",
    "        starting_index = []\n",
    "        for key in self.Key_list:\n",
    "            if key in line:\n",
    "                match_iter = re.finditer(key, line)\n",
    "\n",
    "                for match in match_iter:\n",
    "                    matched_text = [match.group(0)]\n",
    "                    x = match.start()\n",
    "                   \n",
    "                    starting_index.append(x)       \n",
    "            else:\n",
    "                starting_index.append(-1)\n",
    "        sort_string = sorted(starting_index)\n",
    "        \n",
    "\n",
    "        length = len(sort_string)\n",
    "      \n",
    "        for index,obj in enumerate(sort_string):\n",
    "            if obj != -1:\n",
    "                c = starting_index.index(obj)\n",
    "                   \n",
    "                if (index+1) < length:\n",
    "                    next = sort_string[index + 1]\n",
    "                else:\n",
    "                    next = len(text)\n",
    "              \n",
    "                first = len(self.Key_list[c]) + obj\n",
    "                \n",
    "                print(self.Key_list[c],\":\",line[first:next])\n",
    "                                \n",
    "def similar(a, b):\n",
    "    return dl.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def readfile() :\n",
    "    try:\n",
    "        for root, dirs, filenames in os.walk(inpDir):\n",
    "            for f in filenames :\n",
    "                print(\"-\"*40)\n",
    "                print('\\033[1m' + \"For\", f + '\\033[0m')\n",
    "                file1 = (os.path.join(inpDir, f)) \n",
    "                Input_Path = open(file1,'r')\n",
    "                readtext(Input_Path,file1,f)\n",
    "                #print(\"\")\n",
    "    except Exception as e:\n",
    "        print(\"Problem in readfile():\", e)\n",
    "\n",
    "#Reading a file line by line            \n",
    "def readtext(Input_Path,file1,f):\n",
    "    try:\n",
    "        mean = 0\n",
    "        count = 0\n",
    "        with open(file1) as ff: \n",
    "            lines = ff.readlines()   \n",
    "\n",
    "            for i in range(0, len(lines)):\n",
    "               \n",
    "                \n",
    "                line = lines[i]\n",
    "                \n",
    "                if line.strip() == '':\n",
    "                    continue\n",
    "                #line1 = nltk.word_tokenize(line)\n",
    "                #print('\\033[1m' + \"Line:\",line+ '\\033[0m')\n",
    "                max1=0\n",
    "                found = 0\n",
    "                for iterateKeys in range(0, len(dfKey['Keywords'])):\n",
    "                    n = len(dfKey['Keywords'][iterateKeys].strip().split(\" \"))\n",
    "                    \n",
    "                    sixgrams = ngrams(line.split(), n)\n",
    "                    word = None\n",
    "                    \n",
    "                    for grams in sixgrams:\n",
    "                        \n",
    "                        str1 = ' '.join(grams)\n",
    "                        key=str1\n",
    "                        keyword1 = dfKey['Keywords'][iterateKeys]\n",
    "                                         \n",
    "                        max1 = similar(key.lower(), keyword1.lower())\n",
    "                        \n",
    "                        \n",
    "                        if max1>0.8:\n",
    "                            count+=1\n",
    "                            mean+=max1\n",
    "                            #print('\\033[1m' + \"Line:\",line+ '\\033[0m')\n",
    "                            print(\"Keyword:\",dfKey['Keywords'][iterateKeys])\n",
    "                            #print(\"Length:\", n)\n",
    "                            #print(\"Grams:\",grams)\n",
    "                            word = keyword1 \n",
    "                            #print(key, \" \",max1,\" \", word)\n",
    "                            #print(dl.get_close_matches(key,dfKey['Keywords']))\n",
    "                             \n",
    "                            found=1  \n",
    "                            \n",
    "                            try:\n",
    "                                for iterateKeys in range(0, len(dfKey['Keywords'])):\n",
    "                                    list3 = []\n",
    "                                    #print(type(dfKey['Keywords'][iterateKeys]))\n",
    "                                    if dfKey['Keywords'][iterateKeys].lower() in word.lower() :\n",
    "                                        #print(iterateKeys)             \n",
    "                                        list3.append(dfKey['Keywords'][iterateKeys])\n",
    "                                        print(\"Sub Category:\", dfKey['Sub-Category'][iterateKeys])\n",
    "                                        print(\"Category:\",dfKey['Category'][iterateKeys])\n",
    "                                        obj = ExtractData(list3,Input_Path)\n",
    "                                        obj.read_text()\n",
    "                                        \n",
    "                                        global row\n",
    "                                        row+=1\n",
    "                                        ws.write(row,0,f)\n",
    "                                        ws.write(row,1,dfKey['Category'][iterateKeys])\n",
    "                                        ws.write(row,2,dfKey['Sub-Category'][iterateKeys])\n",
    "                                        ws.write(row,3,dfKey['Keywords'][iterateKeys])\n",
    "\n",
    "                                        print(\"\")\n",
    "                                        \n",
    "                            except Exception as e:\n",
    "                                PrintException()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Exception:\",e)\n",
    "    \n",
    "    print(\"\")\n",
    "    if count==0:\n",
    "        print(\"No Keyword\")\n",
    "    else:\n",
    "        mean=mean/count\n",
    "    #print(\"Count:\", count)\n",
    "    #print(\"Mean:\",mean)\n",
    "    \n",
    "    #Input_Path1 = Input_Path\n",
    "    \n",
    "    \n",
    "    wb.save(printPath)\n",
    "if __name__ == '__main__':\n",
    "    readfile()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"\\nExecution Time:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n",
      "0 -1\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import logging \n",
    "\n",
    "class ExtractData():\n",
    "    \n",
    "    def __init__(self,Key_list,Input_Path):\n",
    "        self.Key_list = Key_list\n",
    "        self.Input_Path = Input_Path\n",
    "        \n",
    "    def read_text(self):\n",
    "        \n",
    "        text = self.Input_Path.read()\n",
    "       \n",
    "        for line in text.splitlines():\n",
    "            self.match_keyword(line,text)\n",
    "       \n",
    "    def match_keyword(self,line,text):\n",
    "        \n",
    "        starting_index = []\n",
    "        for key in self.Key_list:\n",
    "            if key in line:\n",
    "                match_iter = re.finditer(key, line)\n",
    "\n",
    "                for match in match_iter:\n",
    "                    matched_text = [match.group(0)]\n",
    "                    x = match.start()\n",
    "                    print(matched_text)\n",
    "                   \n",
    "                    \n",
    "            else:\n",
    "                starting_index.append(-1)\n",
    "        sort_string = sorted(starting_index)\n",
    "        \n",
    "        \n",
    "\n",
    "        length = len(sort_string)\n",
    "      \n",
    "        for index,obj in enumerate(sort_string):\n",
    "            print(index,obj)\n",
    "            if obj != -1:\n",
    "                c = starting_index.index(obj)\n",
    "                \n",
    "                if (index+1) < length:\n",
    "                    next = sort_string[index + 1]\n",
    "                else:\n",
    "                    next = len(text)\n",
    "              \n",
    "                first = len(self.Key_list[c]) + obj\n",
    "                \n",
    "                print(self.Key_list[c],line[first:next])\n",
    "                \n",
    "Key_list = ['DATE']\n",
    "\n",
    "Input_Path = open(r'\\\\brdieshnas1\\AMS\\SOFTWARE_REPOSITORY\\Python\\Auchinto Chatterjee\\Autocorrect + Categorise\\Well_Refined_TXT\\Baker Hughes_2001.txt','r')\n",
    "\n",
    "obj = ExtractData(Key_list,Input_Path)\n",
    "obj.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
